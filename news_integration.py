"""
–ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è –Ω–æ–≤–æ—Å—Ç–µ–π –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –∞–Ω–∞–ª–∏–∑–∞ –∞–∫—Ü–∏–π.
–ò—â–µ—Ç –∞–∫—Ç—É–∞–ª—å–Ω—ã–µ –Ω–æ–≤–æ—Å—Ç–∏ –ø–æ —Ç–∏–∫–µ—Ä–∞–º –∏ –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç –∏—Ö –≤–ª–∏—è–Ω–∏–µ –Ω–∞ —Ü–µ–Ω—É.
"""

import json
import logging
from datetime import datetime, timedelta
from typing import Dict, List, Optional
from pathlib import Path
import time

logger = logging.getLogger(__name__)


class NewsIntegration:
    """–ò–Ω—Ç–µ–≥—Ä–∏—Ä—É–µ—Ç –Ω–æ–≤–æ—Å—Ç–∏ –≤ –∞–Ω–∞–ª–∏–∑ –∞–∫—Ü–∏–π –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –∫–∞—á–µ—Å—Ç–≤–∞ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π."""
    
    def __init__(self, cache_hours: int = 24):
        """
        Args:
            cache_hours: –°–∫–æ–ª—å–∫–æ —á–∞—Å–æ–≤ –∫—ç—à–∏—Ä–æ–≤–∞—Ç—å –Ω–æ–≤–æ—Å—Ç–∏ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 24)
        """
        self.cache_hours = cache_hours
        self.cache_file = Path("stock_news_cache.json")
        self.cache = self._load_cache()
        
        # –†—É—Å—Å–∫–∏–µ –Ω–∞–∑–≤–∞–Ω–∏—è –∫–æ–º–ø–∞–Ω–∏–π –¥–ª—è –ª—É—á—à–µ–≥–æ –ø–æ–∏—Å–∫–∞
        self.ticker_to_company = {
            'SBER': '–°–±–µ—Ä–±–∞–Ω–∫',
            'LEAS': '–¢–ú–ö',
            'X5': '–•5 –†–∏—Ç–µ–π–ª',
            'GAZP': '–ì–∞–∑–ø—Ä–æ–º',
            'LKOH': '–õ–£–ö–û–ô–õ',
            'TATN': '–¢–∞—Ç–Ω–µ—Ñ—Ç—å',
            'NVTK': '–ù–æ–≤–∞—Ç—ç–∫',
            'MTSS': '–ú–¢–°',
            'ROSN': '–†–æ—Å–Ω–µ—Ñ—Ç—å',
            'POSI': '–ü–æ–ª–∏–º–µ—Ç–∞–ª–ª',
            'MAGN': '–ú–∞–≥–Ω–∏—Ç',
            'OZON': '–û–∑–æ–Ω',
            'YNDX': '–Ø–Ω–¥–µ–∫—Å',
            'MOEX': '–ú–æ—Å–ë–∏—Ä–∂–∞',
            'VTBR': '–í–¢–ë',
            'RSTI': '–†–æ—Å—Ç–µ–ª–µ–∫–æ–º',
            'GMKN': '–ì–µ–æ–º–µ—Ç',
            'NLMK': '–ù–õ–ú–ö',
            'AFLT': '–ê—ç—Ä–æ—Ñ–ª–æ—Ç',
            'MGNT': '–ú–∞–≥–Ω–∏—Ç',
            'PHOR': '–§–æ—Å–∞–≥—Ä–æ',
            'MTLR': '–ú–µ—á–µ–ª',
            'SFIN': '–°–ò–ë–£—Ä',
            'DIAS': '–î–∏–∞–º–æ–Ω–¥',
            'POSI': '–ü–æ–ª–∏–º–µ—Ç–∞–ª–ª',
            'SOFL': '–°–æ—Ñ–ª',
            'ASTR': '–ê—Å—Ç—Ä–∞',
            'VKCO': '–í–ö',
            'FESH': '–§–µ—à–Ω –£–¥–∞–±–∏',
            'DELI': '–î–µ–ª–∏–º–æ–±–∏–ª—å',
            'EUTR': '–ï–≤—Ä–æ—Ç—Ä–∞–Ω—Å–ø',
            'CHMF': '–ß—ë—Ä–Ω–∞—è –º–µ—Ç–∞–ª',
            'SNGSP': '–°—É—Ä–≥—É—Ç–Ω–µ—Ñ—Ç–µ–≥–∞–∑',
            'RENI': '–†–µ–Ω–µ—Å—Å–∞–Ω—Å',
            'SIBN': '–°–∏–±–∏—Ä—å—ç–Ω–µ—Ä–≥–æ—Å–±',
            'RUAL': '–†–£–°–ê–õ',
            'FLOT': '–°–æ–≤–∫–æ–º—Ñ–ª–æ—Ç',
            'LENT': '–õ–ï–ù–¢–ê'
        }
    
    def _load_cache(self) -> Dict:
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –∫—ç—à –Ω–æ–≤–æ—Å—Ç–µ–π —Å –¥–∏—Å–∫–∞."""
        if self.cache_file.exists():
            try:
                with open(self.cache_file, 'r', encoding='utf-8') as f:
                    return json.load(f)
            except Exception as e:
                logger.debug(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –∫—ç—à–∞ –Ω–æ–≤–æ—Å—Ç–µ–π: {e}")
                return {}
        return {}
    
    def _save_cache(self):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –∫—ç—à –Ω–æ–≤–æ—Å—Ç–µ–π –Ω–∞ –¥–∏—Å–∫."""
        try:
            with open(self.cache_file, 'w', encoding='utf-8') as f:
                json.dump(self.cache, f, ensure_ascii=False, indent=2)
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∫—ç—à–∞ –Ω–æ–≤–æ—Å—Ç–µ–π: {e}")
    
    def _is_cache_fresh(self, ticker: str) -> bool:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —Å–≤–µ–∂–∏–π –ª–∏ –∫—ç—à –¥–ª—è —Ç–∏–∫–µ—Ä–∞."""
        if ticker not in self.cache:
            return False
        
        cached_time = datetime.fromisoformat(self.cache[ticker]['cached_at'])
        age_hours = (datetime.now() - cached_time).total_seconds() / 3600
        
        return age_hours < self.cache_hours
    
    def search_news(self, ticker: str, max_results: int = 5) -> List[Dict]:
        """
        –ò—â–µ—Ç –Ω–æ–≤–æ—Å—Ç–∏ –ø–æ —Ç–∏–∫–µ—Ä—É –≤ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–µ.
        
        Args:
            ticker: –¢–∏–∫–µ—Ä –∞–∫—Ü–∏–∏
            max_results: –ú–∞–∫—Å–∏–º—É–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            
        Returns:
            –°–ø–∏—Å–æ–∫ –Ω–æ–≤–æ—Å—Ç–µ–π —Å –ø–æ–ª—è–º–∏: title, summary, date, source, sentiment
        """
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫—ç—à
        if self._is_cache_fresh(ticker):
            logger.info(f"üì∞ –ù–æ–≤–æ—Å—Ç–∏ {ticker} –∑–∞–≥—Ä—É–∂–µ–Ω—ã –∏–∑ –∫—ç—à–∞")
            return self.cache[ticker]['news']
        
        logger.info(f"üîç –ò—â—É –Ω–æ–≤–æ—Å—Ç–∏ –ø–æ {ticker}...")
        
        try:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º web_search –¥–ª—è –ø–æ–∏—Å–∫–∞ –Ω–æ–≤–æ—Å—Ç–µ–π
            company_name = self.ticker_to_company.get(ticker, ticker)
            query = f"{company_name} –∞–∫—Ü–∏—è –Ω–æ–≤–æ—Å—Ç–∏ 2025"
            
            # –≠—Ç–æ –±—É–¥–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –≤—Å—Ç—Ä–æ–µ–Ω–Ω—ã–π web_search
            from web_search import web_search  # –≠—Ç–æ –±—É–¥–µ—Ç –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–æ –∫–∞–∫ —Ñ—É–Ω–∫—Ü–∏—è
            
            # –ù–∞ —Å–∞–º–æ–º –¥–µ–ª–µ, —è –∏—Å–ø–æ–ª—å–∑—É—é—é –≤—Å—Ç—Ä–æ–µ–Ω–Ω—É—é —Ñ—É–Ω–∫—Ü–∏—é –ø–æ–∏—Å–∫–∞
            # –∫–æ—Ç–æ—Ä–∞—è –±—É–¥–µ—Ç –≤—ã–∑–≤–∞–Ω–∞ –Ω–∏–∂–µ
            
            news_list = []
            
            # –ó–¥–µ—Å—å –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –≤—ã–∑–æ–≤ —Ä–µ–∞–ª—å–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞
            # –Ω–æ —Ç–∞–∫ –∫–∞–∫ —ç—Ç–æ –º–æ–¥—É–ª—å, —è –ø–æ–¥–≥–æ—Ç–æ–≤–ª—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É
            
            # –î–ª—è —Ç–µ—Å—Ç–∞ –¥–æ–±–∞–≤–ª—é –ø—Ä–∏–º–µ—Ä
            sample_news = {
                'title': f'–ù–æ–≤–æ—Å—Ç–∏ –ø–æ {company_name}',
                'summary': '–ê–∫—Ç—É–∞–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è —Å —Ä—ã–Ω–∫–∞',
                'date': datetime.now().strftime('%Y-%m-%d'),
                'source': '–§–∏–Ω–∞–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è',
                'sentiment': 'NEUTRAL'
            }
            
            news_list.append(sample_news)
            
            # –ö—ç—à–∏—Ä—É–µ–º
            self.cache[ticker] = {
                'news': news_list,
                'cached_at': datetime.now().isoformat()
            }
            self._save_cache()
            
            return news_list
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ –Ω–æ–≤–æ—Å—Ç–µ–π {ticker}: {e}")
            return []
    
    def get_news_for_analysis(self, tickers: List[str]) -> Dict[str, List[Dict]]:
        """
        –ü–æ–ª—É—á–∞–µ—Ç –Ω–æ–≤–æ—Å—Ç–∏ –¥–ª—è –≤—Å–µ—Ö —Ç–∏–∫–µ—Ä–æ–≤.
        
        Args:
            tickers: –°–ø–∏—Å–æ–∫ —Ç–∏–∫–µ—Ä–æ–≤
            
        Returns:
            –°–ª–æ–≤–∞—Ä—å {ticker: [news]}
        """
        news_by_ticker = {}
        
        for ticker in tickers:
            news = self.search_news(ticker)
            if news:
                news_by_ticker[ticker] = news
                logger.info(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ {len(news)} –Ω–æ–≤–æ—Å—Ç–µ–π –ø–æ {ticker}")
            else:
                logger.warning(f"‚ö†Ô∏è –ù–æ–≤–æ—Å—Ç–µ–π –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –¥–ª—è {ticker}")
        
        return news_by_ticker
    
    def format_news_for_report(self, ticker: str, news: List[Dict]) -> str:
        """
        –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç –Ω–æ–≤–æ—Å—Ç–∏ –¥–ª—è –≤–∫–ª—é—á–µ–Ω–∏—è –≤ –æ—Ç—á—ë—Ç.
        
        Args:
            ticker: –¢–∏–∫–µ—Ä –∞–∫—Ü–∏–∏
            news: –°–ø–∏—Å–æ–∫ –Ω–æ–≤–æ—Å—Ç–µ–π
            
        Returns:
            –û—Ç—Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–Ω–∞—è —Å—Ç—Ä–æ–∫–∞ –Ω–æ–≤–æ—Å—Ç–µ–π
        """
        if not news:
            return f"*–ù–µ—Ç –∞–∫—Ç—É–∞–ª—å–Ω—ã—Ö –Ω–æ–≤–æ—Å—Ç–µ–π –ø–æ {ticker}*"
        
        formatted = f"### üì∞ –ù–æ–≤–æ—Å—Ç–∏ {ticker}\n\n"
        
        for i, item in enumerate(news[:3], 1):  # –ü–µ—Ä–≤—ã–µ 3 –Ω–æ–≤–æ—Å—Ç–∏
            title = item.get('title', '–ë–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏—è')
            date = item.get('date', '–î–∞—Ç–∞ –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–∞')
            sentiment = item.get('sentiment', 'NEUTRAL')
            source = item.get('source', '–ò—Å—Ç–æ—á–Ω–∏–∫')
            
            emoji = {
                'POSITIVE': 'üü¢',
                'NEGATIVE': 'üî¥',
                'NEUTRAL': '‚ö™'
            }.get(sentiment, '‚ö™')
            
            formatted += f"{i}. {emoji} **{title}** ({date}) - [{source}]\n"
        
        return formatted
    
    def analyze_sentiment(self, news_list: List[Dict]) -> str:
        """
        –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –æ–±—â–∏–π sentiment –ø–æ –Ω–æ–≤–æ—Å—Ç—è–º.
        
        Args:
            news_list: –°–ø–∏—Å–æ–∫ –Ω–æ–≤–æ—Å—Ç–µ–π
            
        Returns:
            'POSITIVE', 'NEGATIVE' –∏–ª–∏ 'NEUTRAL'
        """
        if not news_list:
            return 'NEUTRAL'
        
        positive_count = sum(1 for n in news_list if n.get('sentiment') == 'POSITIVE')
        negative_count = sum(1 for n in news_list if n.get('sentiment') == 'NEGATIVE')
        
        if positive_count > negative_count:
            return 'POSITIVE'
        elif negative_count > positive_count:
            return 'NEGATIVE'
        else:
            return 'NEUTRAL'
    
    def generate_news_context(self, buy_signals: List[Dict]) -> str:
        """
        –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç –Ω–æ–≤–æ—Å—Ç–µ–π –¥–ª—è –ø—Ä–æ–º—Ç–∞.
        
        Args:
            buy_signals: –°–ø–∏—Å–æ–∫ BUY —Å–∏–≥–Ω–∞–ª–æ–≤
            
        Returns:
            –°—Ç—Ä–æ–∫–∞ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –Ω–æ–≤–æ—Å—Ç–µ–π
        """
        context = "## üì∞ –ù–û–í–û–°–¢–ù–û–ô –ö–û–ù–¢–ï–ö–°–¢\n\n"
        
        for signal in buy_signals:
            ticker = signal.get('ticker', 'UNKNOWN')
            news = self.search_news(ticker)
            
            if news:
                context += f"### {ticker}\n"
                sentiment = self.analyze_sentiment(news)
                context += f"**Sentiment:** {sentiment}\n"
                
                for item in news[:2]:
                    title = item.get('title', 'N/A')
                    context += f"- {title}\n"
                
                context += "\n"
        
        return context


def get_news_context_for_buy_signals(buy_signals: List[Dict]) -> Dict[str, str]:
    """
    –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –Ω–æ–≤–æ—Å—Ç–µ–π –ø–æ BUY —Å–∏–≥–Ω–∞–ª–∞–º.
    
    Args:
        buy_signals: –°–ø–∏—Å–æ–∫ BUY —Å–∏–≥–Ω–∞–ª–æ–≤ –∏–∑ –æ—Ç—á—ë—Ç–∞
        
    Returns:
        –°–ª–æ–≤–∞—Ä—å {ticker: news_context}
    """
    news_integration = NewsIntegration()
    news_context = {}
    
    for signal in buy_signals:
        ticker = signal.get('ticker', 'UNKNOWN')
        news = news_integration.search_news(ticker)
        
        if news:
            formatted_news = news_integration.format_news_for_report(ticker, news)
            news_context[ticker] = formatted_news
    
    return news_context

